---
title: "Databases"
author: "Jonas Kahila"
date: "2024-12-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Databases store data on disk instead of in memory. Some datasets are larger than the available memory on the machine--like raster data. Databases are also useful if data is constantly being updated by other people or processes. Also, databases can store data remotely.

**Queries**

You access data in a database with queries, which return data that is not raw(cooked?) SQL is used for queries

```{r}
library(tidyverse)
library(nycflights13)
library(tictoc)
library(dbplyr)
library(DBI) 
library(RSQLite)
```

## A light database example

**Create database and connect**

```{r}
lite_con = dbConnect(SQLite(), path = ":memory:")

#copy in flights data
copy_to(
  dest = lite_con,
  df = flights,
  name = "flights",
  temporary = F,
  indexes = list(c("year","month", "day"), "carrier", "tailnum", "dest")
)
```

**Work with the database**
```{r}
flights_db = tbl(lite_con, "flights")
class(flights_db)

#dyplr functions are translated by dbplyr to work for databases
#notice R doesn't know how many rows are in the data
head(flights_db)
```

**Work with data normally**
```{r}
flights_db |>
  select(year:day, dep_delay, arr_delay)

flights_db |>
  group_by(dest)|>
  summarize(delay = mean(dep_delay))
```

**This process is lazy** it minimizes the amount of work it does because extra tasks can be time intensive. This is quick, but doesn't actually return anything.
```{r}
tic()
tailnum_delay_db = flights_db |>
  group_by(tailnum)|>
  summarize(mean_delay = mean(dep_delay))|>
  arrange(desc(mean_delay))
toc()
```

This takes much longer. It actually must execute the query when this is called. At the same time, since a real database would make this calculation for you, this can be done quicker with large datasets than it could be done in memory.
```{r}
tic()
head(tailnum_delay_db)
toc()
```


**Bring data into R**

```{r}
#this creates a tibble out of data in the database
tailnum_delay = tailnum_delay_db |> collect()

#ex: application
hist(tailnum_delay$mean_delay)
```


## Look at SQl queries

This is what an SWL query looks like under the hood
```{r}
tailnum_delay_db |> show_query()

```

Trying to execute a query without dbplyr
```{r}
#the dbplyr query looks like this
flights_db |>
  filter(dep_delay > 240)|>
  head(5)|>
  show_query()

# our query looks like this . . and it works
query = "SELECT * FROM flights WHERE dep_delay > 240 LIMIT 5"

dbGetQuery(lite_con, query)
```

**list tables**
```{r}
dbListTables(lite_con)

```

**list fields**
```{r}
dbListFields(lite_con, "flights")

```



## Working with SQL in R markdown can be even easier

```{sql connection=lite_con}
SELECT * 
FROM flights 
WHERE dep_delay > 240 
LIMIT 5

```

```{sql connection=lite_con}
SELECT dep_delay
FROM flights 
WHERE dep_delay > 240 
LIMIT 5

```

```{sql connection=lite_con}
SELECT COUNT(*)
FROM flights 
WHERE dep_delay > 240 
LIMIT 5
```

Count distinct values
```{sql connection=lite_con}
SELECT COUNT(DISTINCT dep_delay)
FROM flights 
WHERE dep_delay > 240
LIMIT 5

```
EX: 
```{sql connection=lite_con}
SELECT distance, air_time, distance / (air_time / 60) AS speed
FROM flights 
LIMIT 10

```

## Joins
**copy weather data**

```{r}
copy_to(
  dest = lite_con,
  df = nycflights13::weather,
  name = "weather",
  temporary = F,
  indexes = list(c("year", "month", "day", "hour"))
)

```

**joining with SQL**
```{sql connection=lite_con}
SELECT *
FROM flights AS f
LEFT JOIN weather AS w
ON f.year = w.year AND f.month = w.month AND f.day = w.day AND f.hour = w.hour
```

```{sql connection=}
SELECT (DISTINCT dest)
from flights
```


```{sql connection=lite_con}

SELECT count(*)
FROM flights
WHERE origin == "BZN" AND dest == "NYC" 

```






