<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol.lst-kix_n3sgm6xt5ux8-5.start{counter-reset:lst-ctn-kix_n3sgm6xt5ux8-5 0}.lst-kix_td0jwgqs27mb-0>li:before{content:"-  "}.lst-kix_n3sgm6xt5ux8-3>li{counter-increment:lst-ctn-kix_n3sgm6xt5ux8-3}.lst-kix_td0jwgqs27mb-4>li:before{content:"-  "}ol.lst-kix_n3sgm6xt5ux8-8.start{counter-reset:lst-ctn-kix_n3sgm6xt5ux8-8 0}.lst-kix_td0jwgqs27mb-1>li:before{content:"-  "}.lst-kix_td0jwgqs27mb-5>li:before{content:"-  "}.lst-kix_td0jwgqs27mb-2>li:before{content:"-  "}.lst-kix_n3sgm6xt5ux8-4>li{counter-increment:lst-ctn-kix_n3sgm6xt5ux8-4}.lst-kix_td0jwgqs27mb-3>li:before{content:"-  "}ul.lst-kix_td0jwgqs27mb-4{list-style-type:none}ol.lst-kix_n3sgm6xt5ux8-4.start{counter-reset:lst-ctn-kix_n3sgm6xt5ux8-4 0}ul.lst-kix_td0jwgqs27mb-3{list-style-type:none}ul.lst-kix_td0jwgqs27mb-6{list-style-type:none}.lst-kix_n3sgm6xt5ux8-5>li:before{content:"" counter(lst-ctn-kix_n3sgm6xt5ux8-5,lower-roman) ". "}.lst-kix_n3sgm6xt5ux8-7>li:before{content:"" counter(lst-ctn-kix_n3sgm6xt5ux8-7,lower-latin) ". "}ul.lst-kix_td0jwgqs27mb-5{list-style-type:none}ul.lst-kix_td0jwgqs27mb-8{list-style-type:none}ul.lst-kix_td0jwgqs27mb-7{list-style-type:none}.lst-kix_n3sgm6xt5ux8-6>li:before{content:"" counter(lst-ctn-kix_n3sgm6xt5ux8-6,decimal) ". "}.lst-kix_n3sgm6xt5ux8-1>li:before{content:"" counter(lst-ctn-kix_n3sgm6xt5ux8-1,lower-latin) ". "}ul.lst-kix_td0jwgqs27mb-0{list-style-type:none}ul.lst-kix_td0jwgqs27mb-2{list-style-type:none}.lst-kix_n3sgm6xt5ux8-0>li:before{content:"" counter(lst-ctn-kix_n3sgm6xt5ux8-0,decimal) ". "}.lst-kix_n3sgm6xt5ux8-8>li:before{content:"" counter(lst-ctn-kix_n3sgm6xt5ux8-8,lower-roman) ". "}ul.lst-kix_td0jwgqs27mb-1{list-style-type:none}ol.lst-kix_n3sgm6xt5ux8-1.start{counter-reset:lst-ctn-kix_n3sgm6xt5ux8-1 0}ol.lst-kix_n3sgm6xt5ux8-7.start{counter-reset:lst-ctn-kix_n3sgm6xt5ux8-7 0}.lst-kix_n3sgm6xt5ux8-2>li:before{content:"" counter(lst-ctn-kix_n3sgm6xt5ux8-2,lower-roman) ". "}.lst-kix_n3sgm6xt5ux8-3>li:before{content:"" counter(lst-ctn-kix_n3sgm6xt5ux8-3,decimal) ". "}.lst-kix_n3sgm6xt5ux8-4>li:before{content:"" counter(lst-ctn-kix_n3sgm6xt5ux8-4,lower-latin) ". "}ol.lst-kix_n3sgm6xt5ux8-3.start{counter-reset:lst-ctn-kix_n3sgm6xt5ux8-3 0}.lst-kix_n3sgm6xt5ux8-6>li{counter-increment:lst-ctn-kix_n3sgm6xt5ux8-6}.lst-kix_n3sgm6xt5ux8-0>li{counter-increment:lst-ctn-kix_n3sgm6xt5ux8-0}.lst-kix_n3sgm6xt5ux8-1>li{counter-increment:lst-ctn-kix_n3sgm6xt5ux8-1}.lst-kix_n3sgm6xt5ux8-7>li{counter-increment:lst-ctn-kix_n3sgm6xt5ux8-7}ol.lst-kix_n3sgm6xt5ux8-0.start{counter-reset:lst-ctn-kix_n3sgm6xt5ux8-0 0}.lst-kix_n3sgm6xt5ux8-2>li{counter-increment:lst-ctn-kix_n3sgm6xt5ux8-2}.lst-kix_n3sgm6xt5ux8-5>li{counter-increment:lst-ctn-kix_n3sgm6xt5ux8-5}.lst-kix_td0jwgqs27mb-8>li:before{content:"-  "}ol.lst-kix_n3sgm6xt5ux8-6.start{counter-reset:lst-ctn-kix_n3sgm6xt5ux8-6 0}.lst-kix_td0jwgqs27mb-6>li:before{content:"-  "}.lst-kix_td0jwgqs27mb-7>li:before{content:"-  "}ol.lst-kix_n3sgm6xt5ux8-2.start{counter-reset:lst-ctn-kix_n3sgm6xt5ux8-2 0}.lst-kix_n3sgm6xt5ux8-8>li{counter-increment:lst-ctn-kix_n3sgm6xt5ux8-8}ol.lst-kix_n3sgm6xt5ux8-0{list-style-type:none}ol.lst-kix_n3sgm6xt5ux8-5{list-style-type:none}ol.lst-kix_n3sgm6xt5ux8-6{list-style-type:none}ol.lst-kix_n3sgm6xt5ux8-7{list-style-type:none}ol.lst-kix_n3sgm6xt5ux8-8{list-style-type:none}ol.lst-kix_n3sgm6xt5ux8-1{list-style-type:none}ol.lst-kix_n3sgm6xt5ux8-2{list-style-type:none}ol.lst-kix_n3sgm6xt5ux8-3{list-style-type:none}ol.lst-kix_n3sgm6xt5ux8-4{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c8{margin-left:36pt;padding-top:0pt;text-indent:-36pt;padding-bottom:0pt;line-height:2.0;orphans:2;widows:2;text-align:left;height:11pt}.c14{margin-left:36pt;padding-top:0pt;text-indent:-36pt;padding-bottom:0pt;line-height:2.0;orphans:2;widows:2;text-align:left}.c12{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c4{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c3{color:#333333;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c5{-webkit-text-decoration-skip:none;color:#1155cc;font-weight:400;text-decoration:underline;text-decoration-skip-ink:none;font-size:12pt;font-family:"Times New Roman"}.c6{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c15{padding-top:0pt;padding-bottom:0pt;line-height:2.0;orphans:2;widows:2;text-align:left}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c7{font-size:12pt;font-family:"Times New Roman";font-weight:400}.c16{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c9{font-size:12pt;font-family:"Times New Roman";font-weight:700}.c11{color:inherit;text-decoration:inherit}.c10{font-style:italic}.c13{color:#333333}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c16 doc-content"><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">A Machine Learning Approach to Avalanche Prediction in Grand Teton National Park</span></p><p class="c2"><span class="c0">ECNS 460 Term Project</span></p><p class="c2"><span class="c0">Cole Germino </span></p><p class="c2"><span class="c0">Jonas Kahila</span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c4">PROBLEM DEFINITION</span></p><p class="c6"><span class="c0">Avalanches pose significant risk to both human life and infrastructure in mountainous regions, especially in high traffic areas like Grand Teton National Park, making accurate forecasting critical for individual and community wellbeing. Despite &nbsp;advancements in atmospheric technology, and snowpack monitoring, predicting avalanches remains a challenge. Traditionally, avalanche forecasting relies on expert opinion and community reported observations, which are limited in scope particularly in remote or sparsely populated regions (most mountainous places). We aim to address these challenges by leveraging machine learning techniques to develop a predictive model for avalanche risk, using weather data and reported avalanche events. This project seeks to explore the relationship between atmospheric variables, and avalanche likelihood, providing a scalable tool to complement expert judgement and enhance avalanche risk assessment. </span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c0">Researchers and businesses have recognized the potential of machine learning to predict the risk of dangerous, naturally occurring events. Prior work has used machine learning methods to predict floods (Tang et. al 2023), wildfires (Hernandez and Hoskins 2024), and Avalanches (Fromm and Sch&ouml;nberger 2022). Hafner et. al (2022) use deep learning methods to locate avalanches in satellite imagery. Machine learning predictions have potential to help individuals understand their own risk, aid businesses facing risk, and improve economic models involving risk of naturally occurring, harmful events.</span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c4">DATA COLLECTION</span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c0">We use a sample of &nbsp;avalanche observations from the Bridger Teton Avalanche Center to train our model. Bridger Teton Avalanche Center provides archives of reported avalanche observations, weather data, and avalanche accidents alongside forecasting and education services. For our sample, we select all avalanches observed within Grand Teton National park between Oct. 24, 2020 and Dec. 31, 2023. For each avalanche in the sample we collect the date and coordinates.</span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c7">We use weather data from the PRISM climate group at Oregon State University, which develops datasets of spatial weather data. </span><span class="c7 c13">PRISM creates daily weather rasters from weather station data using climatologically-aided interpolation. </span><span class="c7">We use daily raster data of mean temperature, minimum temperature, maximum temperature, precipitation, </span><span class="c3">minimum vapor pressure deficit, maximum vapor pressure deficit, and mean dew point at a 4 km resolution, which we access using the PRISM API. After downloading the raster data, we create a multilayer raster in which each layer corresponds to data for a particular variable and a date, while each grid cell responds to a 4km by 4 km area. For each avalanche, we extract daily values for each weather variable from the raster at the location of the avalanche, starting 30 days prior to the observation. </span></p><p class="c1"><span class="c3"></span></p><p class="c6"><span class="c3">As an example, the map below shows the raster of maximum temperature on Jan. 1, 2023 in Grand Teton National Park with the locations of observed avalanches plotted. Extracting max temp for each point would produce a dataframe with max temp on Jan. 1, 2023 at the location of each avalanche.</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 503.00px; height: 358.71px;"><img alt="" src="images/image7.png" style="width: 503.00px; height: 358.71px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c3"></span></p><p class="c6"><span class="c7 c13">Using raster data creates the potential to develop a more advanced machine learning model by scaling the data collection process. The PRISM weather rasters span the United States and are available for dates from Jan. 1981 to May 2024. Raster data of additional variables we might want to add to a more advanced version of our model, such as elevation and land cover, are also publicly available. Expanding the data used to train the model to new locations or time periods, or including additional variables, could be relatively straightforward because extracting data from a raster for an avalanche observation only requires the date and coordinates of the avalanche. </span></p><p class="c6"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c6"><span class="c0">Data collection was one of the challenges of this project, involving working with raster data and an API. We used the R packages terra, sf, and prism to acquire spatial data, manipulate rasters, and extract data.</span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c7">The avalanche observation data only includes observations where avalanches occurred and lacks observations without avalanches to make comparisons with. In other words, the dependent variable has zero variance. We address zero outcome variance by comparing real avalanche observations to simulated avalanche observations, when an avalanche most likely did not occur. The control group is made of simulated avalanches with randomly chosen winter dates during our time period. Simulated avalanches are assigned locations of real avalanche observations for extracting weather data from the raster. This approach resembles a presence vs. background comparison, commonly combined with machine learning in species distribution modeling(</span><span class="c7 c10">Spatial Distribution Models</span><span class="c0">, n.d.).</span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c0">Although we use simulated avalanches with random locations within Grand Teton National Park in the visualization stage of the project, limiting the data used in our machine learning model to only known avalanche locations means our model predicts avalanches using only weather data. The model does not use geographic characteristics, like elevation, land cover, latitude, and longitude and does not predict avalanche terrain or interactions between terrain and weather.</span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c0">The target variable for this study is a binary indicator of avalanche occurrence (1 = avalanche event, 0 = no avalanche, on that specific day). ,We convert this indicator to a categorical factor to make it compatible with classification tasks. To simplify temporal effects of avalanche predictors, we aggregate weather data to create 7-day, 15-day, and 30-day windows, to provide short, medium, and long term features, aiming to represent the cumulative influence of preceding conditions regarding avalanche likelihood. </span></p><p class="c1"><span class="c4"></span></p><p class="c6"><span class="c9">RANDOM FOREST TRAINING</span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c7">Data was split into training and testing subsets, using an 80:20 stratified sampling strategy to present the proportions of the target variable in both subsets. For model training, the Random Forest algorithm was selected for its ability to handle non-linear relationships and avoid overfitting, which was a concern. The parameters Mtry, which determines the number of randomly selected features used at each decision split, was tuned as part of the modeling process. Following this the training set underwent 10-fold cross-validation, partitioning the data into 10 subsets. Each subset was used as a testing set once, while the remaining subsets were used for training.</span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c0">The Random Forest model uses an ensemble of N decision trees, each N is trained on a bootstrapped subset of the training data. Each node within a decision tree, Mtry features are randomly selected from the supporting predictors. Among these, the feature and corresponding split value that maximize information gain were chosen, this random feature selection at each node reduced correlations between trees and promoted diversity within the ensemble, enhancing generalization capabilities. By aggregating predictions from all trees through majority voting, the RF model mitigated overfitting that is often seen with individual decision trees. </span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c7">To determine the optimal Mtry, a grid search was performed over a predefined range of values, the optimal parameter was selected based on cross-validation performance ensuring the model achieved a balance between accuracy and generalizability. Once optimized, the RF was retrained on the entire training set using the chosen Mtry, and predictions were generated by aggregating the outputs from the ensemble of decision trees.</span></p><p class="c6"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 180.00px; height: 145.00px;"><img alt="" src="images/image6.png" style="width: 291.00px; height: 145.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c0">Therefore, Mtry &nbsp;= 3</span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c4">Risk Stratification</span></p><p class="c6"><span class="c0">The random forests probabilistic outputs were stratified into three categories:</span></p><p class="c1"><span class="c0"></span></p><p class="c6"><img src="images/image1.png"><span class="c0">Indicating High Avalanche Risk</span></p><p class="c6"><img src="images/image2.png"><span class="c0">Indicating Moderate Avalanche Risk</span></p><p class="c6"><img src="images/image3.png"><span class="c0">&nbsp;Indicating Low Avalanche Risk </span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c0">Allowing stakeholders to interpret predictions based on an actionable threshold. </span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c4">Custom Model performance</span></p><p class="c6"><span class="c0">Evaluating model performance within the moderate-risk category presented challenges because it is inherently ambiguous, since there are only 2 actual outcomes, an avalanche occurs or it doesn&rsquo;t. To address this, a custom weighted system was developed to assess the models accuracy. A fixed weight of 0.5 is given to moderate predictions, reflecting that a moderate risk prediction is partially valuable, but not fully correct. Then correct high predictions, when an avalanche occurred, were awarded full weight, and similarly with low predictions, when no avalanche occurred. </span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c4">RESULTS</span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c0">The model yielded a weighted accuracy of roughly 63.52%, meaning it accurately predicted an avalanche occurrence, on a given day at a rate of ~ 64%, which is not ideal. However, this &nbsp;suggests that the supporting weather variables have some significance when predicting avalanche occurrences. </span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c0">The top 10 most important predictors from the model, determined by the mean decrease in accuracy are presented in the figure below. Expectedly, short-term precipitation related variables are ranked the highest, indicating that short-term precipitation totals have the strongest influence on predicting avalanche occurrences. Closely following are Temperature predictors and Vapor pressure deficits. While temperature is also expected, vapor pressure deficits reveal interesting insights, suggesting that the shape of the snowpack and crystals have nearly an equally strong effect on avalanches as do temperature and precipitation. </span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 487.50px; height: 357.08px;"><img alt="" src="images/image4.png" style="width: 487.50px; height: 357.08px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c0">The distribution of predicted probabilities for avalanche occurrence is shown in the figure below. The low-risk category is well-separated from the high-risk category, indicating a clear distinction in predictions, with the moderate-risk category bridging the extremes, which is expected. </span></p><p class="c6"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 459.08px; height: 336.03px;"><img alt="" src="images/image5.png" style="width: 459.08px; height: 336.03px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c4"></span></p><p class="c1"><span class="c4"></span></p><p class="c1"><span class="c4"></span></p><p class="c6"><span class="c4">LIMITATIONS</span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c0">This study acknowledges several limitations. First, the avalanche observation data used in the model was sourced exclusively from the Bridger-Teton Avalanche Center, which relies on skier-reported observations. For the purpose of this study, it was assumed that all avalanche events were accurately reported and documented; however, this assumption likely introduces an underreporting bias, as not all avalanche events are likely to have been reported. This underreporting may also impact the control group, as a key assumption in generating random control dates was that no avalanche occurred on those dates, which might not always be accurate. Additionally, the model does not differentiate between human-triggered and natural avalanches, which could introduce variability in the predictors&#39; relationship to avalanche likelihood. Lastly, while the Random Forest Model demonstrated a decent performance, it is important to recognize that data-driven methods are limited in their ability to capture the nuanced domain, and will likely never outperform expert opinion. Therefore, the model should be viewed as a complementary tool rather than a replacement tool when assessing avalanche forecasting and risk assessment. </span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c4">CONCLUSION</span></p><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c0">This study demonstrated the potential of a Random Forest machine learning model, to predict avalanche risk, based on atmospheric data. By leveraging daily weather raster data, and observed avalanche events. The stratification of predictions into risk categories, low, moderate, and high offer insights for stakeholders in avalanche forecasting. However, limitations such as validity of data, and the inherent inability of data-driven methods to outperform expert judgement underscore the importance of using this model as a complementary tool. While this model&rsquo;s performance is insightful, efforts to explore other machine learning models, and diversify the dataset may further improve prediction accuracy and overall applicability. Overall, this study contributes to advancing data-driven approaches to avalanche risk assessment while emphasizing the value of expert opinion in the decision-making process. </span></p><p class="c1"><span class="c0"></span></p><hr style="page-break-before:always;display:none;"><p class="c1"><span class="c0"></span></p><p class="c6"><span class="c4">REFERENCES</span></p><p class="c1"><span class="c0"></span></p><p class="c14"><span class="c7">R. Fromm and C. Sch&ouml;nberger, &ldquo;Estimating the danger of snow avalanches with a machine learning approach using a comprehensive snow cover model,&rdquo; </span><span class="c7 c10">Machine Learning with Applications</span><span class="c7">, vol. 10, p. 100405, 2022, doi: </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://doi.org/10.1016/j.mlwa.2022.100405&amp;sa=D&amp;source=editors&amp;ust=1733362044816311&amp;usg=AOvVaw1NGidxAtJLwIXnj2RaIeUB">https://doi.org/10.1016/j.mlwa.2022.100405</a></span><span class="c0">.</span></p><p class="c8"><span class="c0"></span></p><p class="c14"><span class="c7">E. D. Hafner, P. Barton, R. C. Daudt, J. D. Wegner, K. Schindler, and Y. B&uuml;hler, &ldquo;Automated avalanche mapping from SPOT 6/7 satellite imagery with deep learning: results, evaluation, potential and limitations,&rdquo; </span><span class="c7 c10">The Cryosphere</span><span class="c0">, vol. 16, no. 9, pp. 3517&ndash;3530, 2022, doi: 10.5194/tc-16-3517-2022. </span></p><p class="c8"><span class="c0"></span></p><p class="c14"><span class="c7">K. Hernandez and A. B. Hoskins, &ldquo;Machine learning algorithms applied to wildfire data in California&rsquo;s central valley,&rdquo; </span><span class="c7 c10">Trees, Forests and People</span><span class="c7">, vol. 15, p. 100516, 2024, doi: </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://doi.org/10.1016/j.tfp.2024.100516&amp;sa=D&amp;source=editors&amp;ust=1733362044816853&amp;usg=AOvVaw1-vZzyYa2NQvPQRp1Ov4Vp">https://doi.org/10.1016/j.tfp.2024.100516</a></span><span class="c0">.</span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c14"><span class="c7 c10">Spatial Distribution Models</span><span class="c0">. (n.d.). Spatial Data Science. Retrieved Dec. 4, 2024, from https://rspatial.org/analysis/5-global_regression.html#google_vignette</span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c14"><span class="c7">Y. Tang et al., &ldquo;flood forecasting based on machine learning pattern recognition and dynamic migration of parameters,&rdquo; </span><span class="c7 c10">Journal of Hydrology: Regional Studies</span><span class="c7">, vol. 47, p. 101406, 2023, doi: </span><span class="c5"><a class="c11" href="https://www.google.com/url?q=https://doi.org/10.1016/j.ejrh.2023.101406&amp;sa=D&amp;source=editors&amp;ust=1733362044817404&amp;usg=AOvVaw0FInQpq1x2Ca97R_8L7tk8">https://doi.org/10.1016/j.ejrh.2023.101406</a></span><span class="c0">. </span></p><p class="c8"><span class="c12"></span></p><p class="c14"><span class="c12">AI Disclosure: </span></p><p class="c15"><span class="c12">AI was used to debug coding process and help with syntax, as well as help with grammar and sentence structure for the Write up</span></p></body></html>